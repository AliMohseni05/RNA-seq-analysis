# -*- coding: utf-8 -*-
"""RNA-seq

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19IzvT2AXk6qCaQ5CqNPlvelUNfhKHtxR
"""

!apt-get update

!apt-get install  -y fastqc
!apt-get install -y sra-toolkit
import subprocess

# Download SRA file (replace SRRXXXXXXX with your SRA run accession)
#!prefetch SRRXXXXXXX

# Convert to FASTQ (single-end example)
#!fastq-dump --split-files SRRXXXXXXX.sra

# Download SRA file (replace SRRXXXXXXX with your SRA run accession)
!prefetch SRR9879594

# Convert to FASTQ (single-end example)
#!fastq-dump --split-files SRRXXXXXXX.sra

import subprocess
from pathlib import Path

def download_sra_to_fastq(sra_accession, split_files=True, max_spots=None):
    """
    Download SRA data and convert to FASTQ using SRA Toolkit commands.

    Args:
        sra_accession (str): Valid SRA run accession (e.g., 'SRR11605094')
        split_files (bool): Split paired-end reads into separate files
        max_spots (int or None): Limit number of spots to download

    Returns:
        bool: True if successful, False otherwise
    """
    try:
        # Validate accession format
        if not sra_accession.startswith(('SRR', 'ERR', 'DRR')):
            raise ValueError("Accession must start with SRR, ERR, or DRR")

        # Create SRA directory structure
        sra_dir = Path.home() / "ncbi" / "public" / "sra"
        sra_dir.mkdir(parents=True, exist_ok=True)

        # 1. Download with prefetch (with retries)
        print(f"ðŸ“¥ Downloading {sra_accession}...")
        for attempt in range(3):  # Retry up to 3 times
            try:
                subprocess.run(
                    ['prefetch', sra_accession, '-O', str(sra_dir)],
                    check=True,
                    stderr=subprocess.PIPE
                )
                break
            except subprocess.CalledProcessError as e:
                if attempt == 2:
                    raise
                print(f"âš ï¸ Retry {attempt + 1}/3...")

        # 2. Verify download
        sra_path = sra_dir / f"{sra_accession}.sra"
        if not sra_path.exists():
            raise FileNotFoundError(f"SRA file not found at {sra_path}")

        # 3. Convert to FASTQ
        print(f"âš™ï¸ Converting to FASTQ...")
        fastq_cmd = [
            'fasterq-dump',
            '--outdir', '.',
            '--threads', '4',
            '--verbose'
        ]

        if split_files:
            fastq_cmd.append('--split-files')
        if max_spots:
            fastq_cmd.extend(['--max-spot-id', str(max_spots)])

        fastq_cmd.append(str(sra_path))

        subprocess.run(fastq_cmd, check=True)

        # 4. Cleanup
        sra_path.unlink()
        print(f"âœ… Successfully processed {sra_accession}")
        return True

    except Exception as e:
        print(f"âŒ Failed to process {sra_accession}: {str(e)}")
        return False

import subprocess
import os

def download_rnaseq_sra(srr_id, out_dir='.'):
    """
    Download RNA-seq data from SRA using an SRR code.
    Requires: SRA Toolkit installed and in PATH.

    Args:
        srr_id (str): The SRR accession code (e.g., 'SRR9879594').
        out_dir (str): Directory to save the downloaded files.
    """
    # Ensure output directory exists
    os.makedirs(out_dir, exist_ok=True)

    # Step 1: Download the .sra file using prefetch
    print(f"Downloading SRA file for {srr_id}...")
    subprocess.run(['prefetch', srr_id, '--output-directory', out_dir], check=True)

    # Step 2: Convert .sra to .fastq using fasterq-dump
    sra_path = os.path.join(out_dir, srr_id)
    print(f"Converting {srr_id} to FASTQ...")
    subprocess.run(['fasterq-dump', sra_path, '-O', out_dir], check=True)

    print(f"Download and conversion complete. Files saved in {out_dir}")

# Example usage:
# download_rnaseq_sra('SRR9879594', out_dir='./rna_seq_data')

"""#donwload RNA-seq data"""

list_sra=[]
num=9879602
for i in range(4):
  ssr="SRR"
  srrt= ssr+str(num)
  list_sra.append(srrt)
  num+=1

print(list_sra)
for srr_id in list_sra:
  download_rnaseq_sra(srr_id, out_dir='sra-tomato-4')

def download_sra_to_fastq(sra_accession, split_files=True, max_spots=None):
    """
    Download SRA data and convert to FASTQ using SRA Toolkit commands.

    Args:
        sra_accession (str): The SRA run accession (e.g., 'SRR1234567').
        split_files (bool): Whether to split paired-end reads into separate files.
        max_spots (int or None): Limit number of reads downloaded (None = no limit).

    Returns:
        None. Downloads files to current working directory.
    """
    try:
        # Install SRA Toolkit (skip if already installed)
        print("Installing SRA Toolkit...")
        subprocess.run(['apt-get', 'update'], check=True)
        subprocess.run(['apt-get', 'install', '-y', 'sra-toolkit'], check=True)

        # Download SRA file using prefetch
        print(f"Downloading SRA file for {sra_accession}...")
        subprocess.run(['prefetch', sra_accession], check=True)

        # Build fastq-dump command
        fastq_cmd = ['fastq-dump']
        if split_files:
            fastq_cmd.append('--split-files')
        if max_spots is not None:
            fastq_cmd.extend(['--maxSpotId', str(max_spots)])
        fastq_cmd.append(f'{sra_accession}.sra')

        # Convert SRA to FASTQ
        print(f"Converting {sra_accession}.sra to FASTQ...")
        subprocess.run(fastq_cmd, check=True)

        print("Download and conversion completed successfully.")

    except subprocess.CalledProcessError as e:
        print(f"Error occurred: {e}")

# Example usage:
download_sra_to_fastq('SRP217045', split_files=True, max_spots=100000)

!fastqc /content/sra-tomato-4/SRR9879602.fastq

!apt-get install -y fastp

# Trim single-end FASTQ file
!fastp -i input.fastq -o trimmed_output.fastq -h fastp_report.html -j fastp_report.json

# Trim single-end FASTQ file
!fastp -i /content/SRR2016724_1.fastq -o SRR2016724_1.fastq -h fastp_report.html -j fastp_report.json

#Trim paired-end FASTQ files
!fastp -i input_1.fastq -I input_2.fastq -o trimmed_1.fastq -O trimmed_2.fastq -h fastp_report.html -j fastp_report.json

!wget   https://ftp.ensembl.org/pub/release-114/fasta/mus_musculus/dna/Mus_musculus.GRCm39.dna.toplevel.fa.gz

"""###tomato ref"""

!wget https://ftp.ensemblgenomes.ebi.ac.uk/pub/plants/release-61/fasta/solanum_lycopersicum/dna/Solanum_lycopersicum.SL3.0.dna.toplevel.fa.gz

!gunzip /content/Solanum_lycopersicum.SL3.0.dna.toplevel.fa.gz

!pip install -q condacolab
import condacolab
condacolab.install()

!wget https://cloud.biohpc.swmed.edu/index.php/s/hisat2-220-download/download -O hisat2.zip
!unzip hisat2.zip

!conda install -c bioconda hisat2 -y

!sudo apt-get update
!sudo apt-get -y install hisat2

"""# make ref indexs"""

!gunzip /content/Solanum_lycopersicum.SL3.0.dna.toplevel.fa.gz

!hisat2-build -p 8 /content/Solanum_lycopersicum.SL3.0.dna.toplevel.fa reference_index

"""#maping"""

#p
!hisat2 -p 4 -x reference_index -1 reads_1.fastq -2 reads_2.fastq -S output.sam --summary-file summary.txt

#s
!hisat2 -p 4 -x reference_index -U reads.fastq -S output.sam --summary-file summary.txt

!mkdir random_name

!gunzip /content/Solanum_lycopersicum.SL3.0.dna.toplevel.fa.gz

!hisat2-build /content/Solanum_lycopersicum.SL3.0.dna.toplevel.fa reference_index

"""#sam bam"""

# prompt: i have 8 index.ht2 file and 4 .fastq file i want to make .sam fille with hsat2

import glob

# Get a list of all fastq files in the current directory
fastq_files = glob.glob('*.fastq')

# Assuming paired-end reads and index files are in the same directory
index_prefix = 'reference_index' # Replace with the actual prefix if different

# Iterate through fastq files and run hisat2
for fastq_file in fastq_files:
    # Construct output SAM file name
    output_sam = fastq_file.replace('.fastq', '.sam')

    # Determine if it's a paired-end read (assuming _1.fastq and _2.fastq)
    if '_1.fastq' in fastq_file:
        read2_file = fastq_file.replace('_1.fastq', '_2.fastq')
        if read2_file in fastq_files:
            print(f"Mapping paired-end reads: {fastq_file} and {read2_file} to {output_sam}")
            !hisat2 -p 4 -x {index_prefix} -1 {fastq_file} -2 {read2_file} -S {output_sam} --summary-file {output_sam.replace('.sam', '_summary.txt')}
            # Remove the corresponding _2.fastq from the list to avoid double processing
            fastq_files.remove(read2_file)
        else:
            print(f"Warning: Found {fastq_file} but no matching paired-end file.")
            print(f"Mapping single-end read: {fastq_file} to {output_sam}")
            !hisat2 -p 4 -x {index_prefix} -U {fastq_file} -S {output_sam} --summary-file {output_sam.replace('.sam', '_summary.txt')}
    elif '_2.fastq' in fastq_file:
         # This file will be processed when its _1.fastq counterpart is encountered
         pass # Do nothing, it will be handled by the _1.fastq logic
    else:
        # Assume it's a single-end read if it doesn't have _1 or _2
        print(f"Mapping single-end read: {fastq_file} to {output_sam}")
        !hisat2 -p 4 -x {index_prefix} -U {fastq_file} -S {output_sam} --summary-file {output_sam.replace('.sam', '_summary.txt')}

print("HISAT2 mapping complete for all fastq files.")

!ls -lh *.ht2

!mkdir -p refgene
!mv *.ht2 refgene

!hisat2 -x /content/reference_index/*.ht2 -U /content/sra-tomato-4/*.fastq -S combined_output.sam

list_sra=[]
num=9879602
for i in range(4):
  l=f"SRR{num}.fastq"
  list_sra.append(l)
  num+=1
print(list_sra)

!hisat2 -x /content/reference_index/reference_index \
        -U /content/sra-tomato-4/SRR9879602.fastq\
        -S /content/combined_output.sam

!ls -lh /content/combined_output.sam  # Verify SAM file was created
!head /content/combined_output.sam    # Peek at alignment results

!samtools view -b /content/combined_output.sam > /content/combined_output.bam

!# Sort BAM by genomic coordinates
!samtools sort -@ 4 -o sample.sorted.bam /content/combined_output.bam

# Index the sorted BAM
!samtools index sample.sorted.bam

!pip install HTSeq  # Install HTSeq Python package
!htseq-count --help # Verify installation

!wget  https://ftp.ensemblgenomes.ebi.ac.uk/pub/plants/release-61/gff3/solanum_lycopersicum/Solanum_lycopersicum.SL3.0.61.chr.gff3.gz

!gunzip /content/Solanum_lycopersicum.SL3.0.61.chr.gff3.gz

!htseq-count -f bam -s no sample.sorted.bam /content/tomato.gtf > counts.txt

!htseq-count \
  -f bam \
  -s no \               # Strandedness: adjust if needed ('yes' or 'reverse')
  -r pos \              # BAM is coordinate-sorted
  -t exon \             # Count exons (common for GFF3)
  -i Parent \           # Use "Parent" to link exons to genes
  sample.sorted.bam \
  Solanum_lycopersicum.SL3.0.61.chr.gff3 \
  > counts.txt

# Inspect the GFF3 structure (e.g., for gene/exon entries):
!zcat /content/Solanum_lycopersicum.SL3.0.61.chr.gff3 | grep -E "\tgene\t|\texon\t|\tmRNA\t" | head -n 5 | cut -f9

# Install gffread
!apt-get install gffread

# Convert GFF3 â†’ GTF
!gffread Solanum_lycopersicum.SL3.0.61.chr.gff3 -T -o tomato.gtf

# Now run htseq-count with the GTF
!htseq-count \
  -f bam \
  -s no \
  -r pos \
  tomato.sorted.bam \
  tomato.gtf \
  > counts.txt